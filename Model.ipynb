{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf7e094-7101-48ae-85db-5d4daab5c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65178a37-091b-428a-9f2d-743e73dd27c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>...</th>\n",
       "      <th>payment_sequential</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>payment_installments</th>\n",
       "      <th>payment_value</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "      <td>7c396fd4830fd04220f754e42b4e5bff</td>\n",
       "      <td>3149</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "      <td>7c396fd4830fd04220f754e42b4e5bff</td>\n",
       "      <td>3149</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>voucher</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "      <td>7c396fd4830fd04220f754e42b4e5bff</td>\n",
       "      <td>3149</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>voucher</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "      <td>af07308b275d755c9edb36a90c618231</td>\n",
       "      <td>47813</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>boleto</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.46</td>\n",
       "      <td>8d5266042046a06655c8db133d120ba5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Muito boa a loja</td>\n",
       "      <td>Muito bom o produto.</td>\n",
       "      <td>2018-08-08 00:00:00</td>\n",
       "      <td>2018-08-08 18:37:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "      <td>3a653a41f6f9fc3d2a113cf8398680e8</td>\n",
       "      <td>75265</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>3.0</td>\n",
       "      <td>179.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118441</th>\n",
       "      <td>63943bddc261676b46f01ca7ac2f7bd8</td>\n",
       "      <td>1fca14ff2861355f6e5f14306ff977a7</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-06 12:58:58</td>\n",
       "      <td>2018-02-06 13:10:37</td>\n",
       "      <td>2018-02-07 23:22:42</td>\n",
       "      <td>2018-02-28 17:37:56</td>\n",
       "      <td>2018-03-02 00:00:00</td>\n",
       "      <td>da62f9e57a76d978d02ab5362c509660</td>\n",
       "      <td>11722</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>3.0</td>\n",
       "      <td>195.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118442</th>\n",
       "      <td>83c1379a015df1e13d02aae0204711ab</td>\n",
       "      <td>1aa71eb042121263aafbe80c1b562c9c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-08-27 14:46:43</td>\n",
       "      <td>2017-08-27 15:04:16</td>\n",
       "      <td>2017-08-28 20:52:26</td>\n",
       "      <td>2017-09-21 11:24:17</td>\n",
       "      <td>2017-09-27 00:00:00</td>\n",
       "      <td>737520a9aad80b3fbbdad19b66b37b30</td>\n",
       "      <td>45920</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>5.0</td>\n",
       "      <td>271.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118443</th>\n",
       "      <td>11c177c8e97725db2631073c19f07b62</td>\n",
       "      <td>b331b74b18dc79bcdf6532d51e1637c1</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-01-08 21:28:27</td>\n",
       "      <td>2018-01-08 21:36:21</td>\n",
       "      <td>2018-01-12 15:35:03</td>\n",
       "      <td>2018-01-25 23:32:54</td>\n",
       "      <td>2018-02-15 00:00:00</td>\n",
       "      <td>5097a5312c8b157bb7be58ae360ef43c</td>\n",
       "      <td>28685</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>4.0</td>\n",
       "      <td>441.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118444</th>\n",
       "      <td>11c177c8e97725db2631073c19f07b62</td>\n",
       "      <td>b331b74b18dc79bcdf6532d51e1637c1</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-01-08 21:28:27</td>\n",
       "      <td>2018-01-08 21:36:21</td>\n",
       "      <td>2018-01-12 15:35:03</td>\n",
       "      <td>2018-01-25 23:32:54</td>\n",
       "      <td>2018-02-15 00:00:00</td>\n",
       "      <td>5097a5312c8b157bb7be58ae360ef43c</td>\n",
       "      <td>28685</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>4.0</td>\n",
       "      <td>441.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118445</th>\n",
       "      <td>66dea50a8b16d9b4dee7af250b4be1a5</td>\n",
       "      <td>edb027a75a1449115f6b43211ae02a24</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-03-08 20:57:30</td>\n",
       "      <td>2018-03-09 11:20:28</td>\n",
       "      <td>2018-03-09 22:11:59</td>\n",
       "      <td>2018-03-16 13:08:30</td>\n",
       "      <td>2018-04-03 00:00:00</td>\n",
       "      <td>60350aa974b26ff12caad89e55993bd6</td>\n",
       "      <td>83750</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>debit_card</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118446 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                order_id                       customer_id  \\\n",
       "0       e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1       e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "2       e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "3       53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "4       47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "...                                  ...                               ...   \n",
       "118441  63943bddc261676b46f01ca7ac2f7bd8  1fca14ff2861355f6e5f14306ff977a7   \n",
       "118442  83c1379a015df1e13d02aae0204711ab  1aa71eb042121263aafbe80c1b562c9c   \n",
       "118443  11c177c8e97725db2631073c19f07b62  b331b74b18dc79bcdf6532d51e1637c1   \n",
       "118444  11c177c8e97725db2631073c19f07b62  b331b74b18dc79bcdf6532d51e1637c1   \n",
       "118445  66dea50a8b16d9b4dee7af250b4be1a5  edb027a75a1449115f6b43211ae02a24   \n",
       "\n",
       "       order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0         delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1         delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "2         delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "3         delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "4         delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "...             ...                      ...                  ...   \n",
       "118441    delivered      2018-02-06 12:58:58  2018-02-06 13:10:37   \n",
       "118442    delivered      2017-08-27 14:46:43  2017-08-27 15:04:16   \n",
       "118443    delivered      2018-01-08 21:28:27  2018-01-08 21:36:21   \n",
       "118444    delivered      2018-01-08 21:28:27  2018-01-08 21:36:21   \n",
       "118445    delivered      2018-03-08 20:57:30  2018-03-09 11:20:28   \n",
       "\n",
       "       order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0               2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1               2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "2               2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "3               2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "4               2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "...                             ...                           ...   \n",
       "118441          2018-02-07 23:22:42           2018-02-28 17:37:56   \n",
       "118442          2017-08-28 20:52:26           2017-09-21 11:24:17   \n",
       "118443          2018-01-12 15:35:03           2018-01-25 23:32:54   \n",
       "118444          2018-01-12 15:35:03           2018-01-25 23:32:54   \n",
       "118445          2018-03-09 22:11:59           2018-03-16 13:08:30   \n",
       "\n",
       "       order_estimated_delivery_date                customer_unique_id  \\\n",
       "0                2017-10-18 00:00:00  7c396fd4830fd04220f754e42b4e5bff   \n",
       "1                2017-10-18 00:00:00  7c396fd4830fd04220f754e42b4e5bff   \n",
       "2                2017-10-18 00:00:00  7c396fd4830fd04220f754e42b4e5bff   \n",
       "3                2018-08-13 00:00:00  af07308b275d755c9edb36a90c618231   \n",
       "4                2018-09-04 00:00:00  3a653a41f6f9fc3d2a113cf8398680e8   \n",
       "...                              ...                               ...   \n",
       "118441           2018-03-02 00:00:00  da62f9e57a76d978d02ab5362c509660   \n",
       "118442           2017-09-27 00:00:00  737520a9aad80b3fbbdad19b66b37b30   \n",
       "118443           2018-02-15 00:00:00  5097a5312c8b157bb7be58ae360ef43c   \n",
       "118444           2018-02-15 00:00:00  5097a5312c8b157bb7be58ae360ef43c   \n",
       "118445           2018-04-03 00:00:00  60350aa974b26ff12caad89e55993bd6   \n",
       "\n",
       "        customer_zip_code_prefix  ... payment_sequential payment_type  \\\n",
       "0                           3149  ...                1.0  credit_card   \n",
       "1                           3149  ...                3.0      voucher   \n",
       "2                           3149  ...                2.0      voucher   \n",
       "3                          47813  ...                1.0       boleto   \n",
       "4                          75265  ...                1.0  credit_card   \n",
       "...                          ...  ...                ...          ...   \n",
       "118441                     11722  ...                1.0  credit_card   \n",
       "118442                     45920  ...                1.0  credit_card   \n",
       "118443                     28685  ...                1.0  credit_card   \n",
       "118444                     28685  ...                1.0  credit_card   \n",
       "118445                     83750  ...                1.0   debit_card   \n",
       "\n",
       "        payment_installments payment_value                         review_id  \\\n",
       "0                        1.0         18.12                               NaN   \n",
       "1                        1.0          2.00                               NaN   \n",
       "2                        1.0         18.59                               NaN   \n",
       "3                        1.0        141.46  8d5266042046a06655c8db133d120ba5   \n",
       "4                        3.0        179.12                               NaN   \n",
       "...                      ...           ...                               ...   \n",
       "118441                   3.0        195.00                               NaN   \n",
       "118442                   5.0        271.01                               NaN   \n",
       "118443                   4.0        441.16                               NaN   \n",
       "118444                   4.0        441.16                               NaN   \n",
       "118445                   1.0         86.86                               NaN   \n",
       "\n",
       "       review_score  review_comment_title  review_comment_message  \\\n",
       "0               NaN                   NaN                     NaN   \n",
       "1               NaN                   NaN                     NaN   \n",
       "2               NaN                   NaN                     NaN   \n",
       "3               4.0      Muito boa a loja    Muito bom o produto.   \n",
       "4               NaN                   NaN                     NaN   \n",
       "...             ...                   ...                     ...   \n",
       "118441          NaN                   NaN                     NaN   \n",
       "118442          NaN                   NaN                     NaN   \n",
       "118443          NaN                   NaN                     NaN   \n",
       "118444          NaN                   NaN                     NaN   \n",
       "118445          NaN                   NaN                     NaN   \n",
       "\n",
       "       review_creation_date  review_answer_timestamp  \n",
       "0                       NaN                      NaN  \n",
       "1                       NaN                      NaN  \n",
       "2                       NaN                      NaN  \n",
       "3       2018-08-08 00:00:00      2018-08-08 18:37:50  \n",
       "4                       NaN                      NaN  \n",
       "...                     ...                      ...  \n",
       "118441                  NaN                      NaN  \n",
       "118442                  NaN                      NaN  \n",
       "118443                  NaN                      NaN  \n",
       "118444                  NaN                      NaN  \n",
       "118445                  NaN                      NaN  \n",
       "\n",
       "[118446 rows x 40 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert csv to dataframe\n",
    "df_cleaned=pd.read_csv(r\"E:\\E-commerce_project\\dataset ecom\\combined_data.csv\")\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb1034b2-c5b0-453f-8b4a-087d83909f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless columns\n",
    "df_model = df_cleaned.drop(columns=[\n",
    "    'order_id', 'customer_id', 'product_id', 'seller_id', \n",
    "    'review_id', 'review_creation_date', 'product_category_name_english'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7efd75f2-b112-4eec-ba7a-10d2d2ac031f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for model training...\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate delay in days\n",
    "def calculate_delay(row):\n",
    "    \"\"\"Calculate the delay between estimated and actual delivery date in days\"\"\"\n",
    "    if pd.isnull(row['order_delivered_customer_date']):\n",
    "        return np.nan\n",
    "    \n",
    "    estimated_date = pd.to_datetime(row['order_estimated_delivery_date'])\n",
    "    delivered_date = pd.to_datetime(row['order_delivered_customer_date'])\n",
    "    \n",
    "    # Negative values mean early delivery, positive values mean delay\n",
    "    delay = (delivered_date - estimated_date).days\n",
    "    \n",
    "    return delay\n",
    "\n",
    "# Data Preparation\n",
    "print(\"Preparing data for model training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5eed1dd-6ac4-4660-8b0d-84f60d5b48ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime columns\n",
    "datetime_columns = [\n",
    "    'order_purchase_timestamp', \n",
    "    'order_approved_at', \n",
    "    'order_delivered_carrier_date', \n",
    "    'order_delivered_customer_date', \n",
    "    'order_estimated_delivery_date',\n",
    "    'shipping_limit_date',\n",
    "    'review_creation_date',\n",
    "    'review_answer_timestamp'\n",
    "]\n",
    "\n",
    "for col in datetime_columns:\n",
    "    if col in df_cleaned.columns:\n",
    "        df_cleaned[col] = pd.to_datetime(df_cleaned[col], errors='coerce')\n",
    "\n",
    "# Calculate delivery delay for each order\n",
    "df_cleaned['delivery_delay'] = df_cleaned.apply(calculate_delay, axis=1)\n",
    "\n",
    "# Filter for delivered orders only to have valid target values\n",
    "delivered_orders = df_cleaned[df_cleaned['order_status'] == 'delivered'].copy()\n",
    "\n",
    "# Calculate time intervals\n",
    "delivered_orders['approval_time'] = (delivered_orders['order_approved_at'] - \n",
    "                                    delivered_orders['order_purchase_timestamp']).dt.total_seconds() / 3600  # in hours\n",
    "delivered_orders['carrier_time'] = (delivered_orders['order_delivered_carrier_date'] - \n",
    "                                   delivered_orders['order_approved_at']).dt.total_seconds() / 3600  # in hours\n",
    "delivered_orders['estimated_wait_time'] = (delivered_orders['order_estimated_delivery_date'] - \n",
    "                                          delivered_orders['order_purchase_timestamp']).dt.total_seconds() / (3600 * 24)  # in days\n",
    "\n",
    "# Create distance features\n",
    "delivered_orders['same_state'] = (delivered_orders['seller_state'] == delivered_orders['customer_state']).astype(int)\n",
    "delivered_orders['same_city'] = (delivered_orders['seller_city'] == delivered_orders['customer_city']).astype(int)\n",
    "\n",
    "# Calculate product volume\n",
    "delivered_orders['product_volume_cm3'] = (delivered_orders['product_length_cm'] * \n",
    "                                         delivered_orders['product_height_cm'] * \n",
    "                                         delivered_orders['product_width_cm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba307d4b-8f27-4b8e-b1bb-ad878eade387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values in product features\n",
    "for col in ['product_weight_g', 'product_volume_cm3']:\n",
    "    delivered_orders[col].fillna(delivered_orders[col].median(), inplace=True)\n",
    "\n",
    "# Extract month, day of week, and hour from purchase timestamp for seasonality\n",
    "delivered_orders['purchase_month'] = delivered_orders['order_purchase_timestamp'].dt.month\n",
    "delivered_orders['purchase_day_of_week'] = delivered_orders['order_purchase_timestamp'].dt.dayofweek\n",
    "delivered_orders['purchase_hour'] = delivered_orders['order_purchase_timestamp'].dt.hour\n",
    "\n",
    "# Create payment features\n",
    "delivered_orders['total_payment'] = delivered_orders['payment_value']\n",
    "delivered_orders['payment_installments'] = delivered_orders['payment_installments'].fillna(1)\n",
    "\n",
    "# Group data by order_id to handle multiple items per order\n",
    "# First, select features that need to be aggregated\n",
    "item_features = [\n",
    "    'order_item_id', 'price', 'freight_value', \n",
    "    'product_weight_g', 'product_volume_cm3', \n",
    "    'product_photos_qty', 'payment_value'\n",
    "]\n",
    "\n",
    "# Aggregate data at order level\n",
    "order_agg = delivered_orders.groupby('order_id').agg({\n",
    "    'order_item_id': 'count',                # Number of items in the order\n",
    "    'price': 'sum',                          # Total price of the order\n",
    "    'freight_value': 'sum',                  # Total freight value\n",
    "    'product_weight_g': 'sum',               # Total weight\n",
    "    'product_volume_cm3': 'sum',             # Total volume\n",
    "    'product_photos_qty': 'mean',            # Average photos per product\n",
    "    'payment_installments': 'max',           # Max installments\n",
    "    'payment_value': 'sum',                  # Total payment value\n",
    "    'review_score': 'first'                  # Review score (assuming one per order)\n",
    "}).reset_index()\n",
    "# Get features that should be unique per order\n",
    "order_features = delivered_orders.drop_duplicates(subset='order_id')\n",
    "\n",
    "# Select columns that should be unique per order\n",
    "unique_columns = [\n",
    "    'order_id', 'customer_id', 'order_status', \n",
    "    'order_purchase_timestamp', 'order_approved_at', \n",
    "    'order_delivered_carrier_date', 'order_delivered_customer_date', \n",
    "    'order_estimated_delivery_date', 'customer_zip_code_prefix', \n",
    "    'customer_city', 'customer_state', 'seller_id', \n",
    "    'seller_zip_code_prefix', 'seller_city', 'seller_state',\n",
    "    'same_state', 'same_city', 'purchase_month', \n",
    "    'purchase_day_of_week', 'purchase_hour',\n",
    "    'approval_time', 'carrier_time', 'estimated_wait_time', \n",
    "    'delivery_delay', 'payment_type'\n",
    "]\n",
    "\n",
    "# Select only columns that exist in order_features\n",
    "existing_columns = [col for col in unique_columns if col in order_features.columns]\n",
    "order_features = order_features[existing_columns]\n",
    "\n",
    "# Merge aggregated data with order features\n",
    "final_orders = order_features.merge(order_agg, on='order_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea4a1991-4f31-4cd6-82a6-310a40f1c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training\n",
    "feature_columns = [\n",
    "    'purchase_month', 'purchase_day_of_week', 'purchase_hour',\n",
    "    'approval_time', 'carrier_time', 'estimated_wait_time',\n",
    "    'same_state', 'same_city', 'order_item_id',  # order_item_id represents item count after aggregation\n",
    "    'price', 'freight_value', 'product_weight_g', 'product_volume_cm3',\n",
    "    'payment_installments', 'payment_value'\n",
    "]\n",
    "\n",
    "# Make sure all feature columns exist in the dataset\n",
    "feature_columns = [col for col in feature_columns if col in final_orders.columns]\n",
    "\n",
    "# Prepare features and target\n",
    "X = final_orders[feature_columns].copy()\n",
    "y = final_orders['delivery_delay'].copy()\n",
    "\n",
    "# Handle missing values\n",
    "for col in X.columns:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        if X[col].dtype in ['int64', 'float64']:\n",
    "            X[col].fillna(X[col].median(), inplace=True)\n",
    "        else:\n",
    "            X[col].fillna(X[col].mode()[0], inplace=True)\n",
    "\n",
    "# Add payment_type as a feature if it exists\n",
    "if 'payment_type' in final_orders.columns:\n",
    "    payment_dummies = pd.get_dummies(final_orders['payment_type'], prefix='payment')\n",
    "    X = pd.concat([X, payment_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "592da167-3ab8-4c2c-be28-8a68a4a00e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (77182, 19)\n",
      "Testing set shape: (19296, 19)\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e81b97a6-23a2-4bdf-afc5-909109b8bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical and numerical features\n",
    "categorical_features = ['purchase_month', 'purchase_day_of_week', 'purchase_hour', 'same_state', 'same_city']\n",
    "categorical_features = [col for col in categorical_features if col in X.columns]\n",
    "\n",
    "numerical_features = [col for col in X.columns if col not in categorical_features \n",
    "                      and not col.startswith('payment_')]  # Exclude dummy variables\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # This will pass through the payment dummy variables\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "170a1418-57b6-4024-938c-ba9c23e6c7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Linear Regression...\n",
      "  MAE: 4.61 days\n",
      "  RMSE: 7.66 days\n",
      "  R²: 0.4296\n",
      "\n",
      "Training Random Forest...\n",
      "  MAE: 4.54 days\n",
      "  RMSE: 7.68 days\n",
      "  R²: 0.4269\n",
      "\n",
      "Training Gradient Boosting...\n",
      "  MAE: 4.47 days\n",
      "  RMSE: 7.59 days\n",
      "  R²: 0.4391\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate multiple models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Train model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R²': r2,\n",
    "        'pipeline': pipeline\n",
    "    }\n",
    "    \n",
    "    print(f\"  MAE: {mae:.2f} days\")\n",
    "    print(f\"  RMSE: {rmse:.2f} days\")\n",
    "    print(f\"  R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8e6e1cd-1706-45ba-adbf-9719d2a26556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model: Gradient Boosting with MAE: 4.47 days\n"
     ]
    }
   ],
   "source": [
    "# Find the best model\n",
    "best_model = min(results.items(), key=lambda x: x[1]['MAE'])\n",
    "print(f\"\\nBest model: {best_model[0]} with MAE: {best_model[1]['MAE']:.2f} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24eab69c-bfac-4a47-8277-46ad5cc72b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing hyperparameter tuning for Gradient Boosting...\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for the best model\n",
    "print(\"\\nPerforming hyperparameter tuning for Gradient Boosting...\")\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200],\n",
    "    'model__learning_rate': [0.05, 0.1],\n",
    "    'model__max_depth': [3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b690be83-9e5b-46fb-85a3-3d33ec3b400e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline with Gradient Boosting\n",
    "gb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(\n",
    "    gb_pipeline,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a26b5e0-b524-4150-8384-f763ec4053b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned model performance:\n",
      "  MAE: 4.34 days\n",
      "  RMSE: 7.47 days\n",
      "  R²: 0.4576\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the tuned model\n",
    "best_gb = grid_search.best_estimator_\n",
    "y_pred_tuned = best_gb.predict(X_test)\n",
    "\n",
    "mae_tuned = mean_absolute_error(y_test, y_pred_tuned)\n",
    "rmse_tuned = np.sqrt(mean_squared_error(y_test, y_pred_tuned))\n",
    "r2_tuned = r2_score(y_test, y_pred_tuned)\n",
    "\n",
    "print(f\"Tuned model performance:\")\n",
    "print(f\"  MAE: {mae_tuned:.2f} days\")\n",
    "print(f\"  RMSE: {rmse_tuned:.2f} days\")\n",
    "print(f\"  R²: {r2_tuned:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1017bae-381b-4c19-bcba-23976de54f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 4.44\n",
      "RMSE: 7.56\n",
      "R²: 0.4439\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split your data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize model\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "\n",
    "# Fit\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0e4edf6-308d-4ad4-b77b-3293eaec22f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.3],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,\n",
    "    scoring='r2',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf4ae82a-8b95-4ee6-a714-7a1734fb455d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      " {'subsample': 0.8, 'reg_lambda': 1.5, 'reg_alpha': 0.1, 'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'gamma': 0.1, 'colsample_bytree': 0.6}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters:\\n\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4aa6fe88-4f3a-470a-85cd-9aad8c3eb3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV R² Score: 0.4478\n"
     ]
    }
   ],
   "source": [
    "print(\"Best CV R² Score: {:.4f}\".format(random_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5122116-ebb6-41c1-90d1-fd807c474653",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90591f18-eda4-4b07-a5df-e4fb7dc03def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 4.34\n",
      "RMSE: 7.49\n",
      "R²: 0.4536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "741636ee-680c-4139-bf88-8395106c306a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked MAE: 4.33\n",
      "Stacked RMSE: 7.44\n",
      "Stacked R²: 0.4609\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# 👇 Insert your tuned Gradient Boosting params here\n",
    "gbr_best = GradientBoostingRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 👇 Use the best XGBoost params from random_search\n",
    "xgb_best = XGBRegressor(**random_search.best_params_)\n",
    "\n",
    "# Base models\n",
    "base_models = [\n",
    "    ('xgb', xgb_best),\n",
    "    ('gbr', gbr_best)\n",
    "]\n",
    "\n",
    "# Meta model\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "# Stacking model\n",
    "stacked_model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "# Fit model\n",
    "stacked_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_stack = stacked_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_test, y_pred_stack)\n",
    "rmse = mean_squared_error(y_test, y_pred_stack, squared=False)\n",
    "r2 = r2_score(y_test, y_pred_stack)\n",
    "\n",
    "print(f\"Stacked MAE: {mae:.2f}\")\n",
    "print(f\"Stacked RMSE: {rmse:.2f}\")\n",
    "print(f\"Stacked R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9a7dfda-c482-427b-9fa7-0fa5c67e3ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_stacked_model.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(stacked_model, 'final_stacked_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e2bd58-7e86-4793-be77-938c6937d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted delays\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_tuned, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Delay (days)')\n",
    "plt.ylabel('Predicted Delay (days)')\n",
    "plt.title('Actual vs Predicted Delivery Delays')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot error distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "errors = y_test - y_pred_tuned\n",
    "plt.hist(errors, bins=30)\n",
    "plt.xlabel('Prediction Error (days)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Prediction Errors')\n",
    "plt.axvline(x=0, color='r', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the model\n",
    "import joblib\n",
    "joblib.dump(best_gb, 'olist_delivery_delay_model.pkl')\n",
    "\n",
    "print(\"\\nModel saved as 'olist_delivery_delay_model.pkl'\")\n",
    "print(\"You can load it using: model = joblib.load('olist_delivery_delay_model.pkl')\")\n",
    "\n",
    "# Function to predict delivery delay for new orders\n",
    "def predict_delivery_delay(new_data):\n",
    "    \"\"\"\n",
    "    Predict delivery delay for new orders\n",
    "    \n",
    "    Parameters:\n",
    "    new_data (DataFrame): DataFrame with the same features used for training\n",
    "    \n",
    "    Returns:\n",
    "    array: Predicted delays in days\n",
    "    \"\"\"\n",
    "    # Make sure new_data has all required columns\n",
    "    required_cols = set(feature_columns)\n",
    "    if not required_cols.issubset(set(new_data.columns)):\n",
    "        missing = list(required_cols - set(new_data.columns))\n",
    "        print(f\"Missing columns: {missing}\")\n",
    "        raise ValueError(\"New data must contain all feature columns used for training\")\n",
    "    \n",
    "    # If payment_type was used in training, ensure it's properly encoded\n",
    "    if 'payment_type' in final_orders.columns:\n",
    "        payment_types = final_orders['payment_type'].unique()\n",
    "        for payment in payment_types:\n",
    "            col_name = f'payment_{payment}'\n",
    "            if col_name not in new_data.columns:\n",
    "                new_data[col_name] = 0\n",
    "            \n",
    "    return best_gb.predict(new_data[X.columns])\n",
    "\n",
    "print(\"\\nModel training complete! Use the predict_delivery_delay() function to make predictions on new orders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793949ef-d8c4-488c-9a54-1417d2e3756b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
